#!/usr/bin/env python
# coding: utf-8

# Experiment that train in batches by month and test in the next month.

# In[1]:


# %matplotlib widget
# get_ipython().run_line_magic('matplotlib', 'inline')


# Open csv with pandas:

# In[2]:


import pandas as pd
import numpy as np
import scipy.sparse as sp

for TRAIN_NROWS in [258420]:
    # CSV location
    CSV = "androbin_20_final.csv.zip"


    # In[2]:


    COLS = ["resource.entry", "source.class.package", "manifest.permission", "manifest.activity", "manifest.action", "manifest.category", "manifest.feature", "source.method.name", "label", "meta.vt.date"]

    LABEL_COL = "label"

    TIME_COL = "meta.vt.date"
    # read data
    data = pd.read_csv(CSV,compression='zip',keep_default_na=False,usecols=COLS)#,nrows=10000)

    # get labels (0 = goodware, 1 = malware)
    labels = data[LABEL_COL]
    # remove not used columns
    UNUSED_COLUMNS = ["label", "meta.vt.date"]
    # declare submission_date as date time
    data[TIME_COL] =  pd.to_datetime(data[TIME_COL])




    # Group data by months and create subsets to train and test:

    # In[4]:


    # arrays to save X and y for train data
    # initial_year = 2011
    # dataTrain = data[data.submission_date.dt.year<=initial_year]
    # dataTest = data[data.submission_date.dt.year>initial_year]
    # TRAIN_NROWS = 24198
    # initial_year = TRAIN_NROWS
    # dataTrain = data.head(TRAIN_NROWS)
    # dataTest = data.iloc[TRAIN_NROWS:]
    dataTrain = data.head(TRAIN_NROWS)
    dataTest = data.iloc[TRAIN_NROWS:]
    # get years and month
    trainYears = dataTrain[TIME_COL].dt.year.values
    trainMonths = dataTrain[TIME_COL].dt.month.values
    testYears = dataTest[TIME_COL].dt.year.values
    testMonths = dataTest[TIME_COL].dt.month.values
    # get labels
    y_train = np.array(dataTrain[LABEL_COL])
    y_test = np.array(dataTest[LABEL_COL])
    # get values
    # X_dataTrain = dataTrain.values
    # X_dataTest = dataTest.values

    # Feature extraction method:

    # In[5]:


    def feature_extraction(X_dataTrain, X_dataTest, columns=None):
        from sklearn.feature_extraction.text import TfidfVectorizer
        # initialize X_train and X_test
        X_train = None
        X_test = None
        # save models used
        models = []
        # iterate over each column of X_dataTrain
        for i in range(X_dataTrain.shape[1]):
            # try:
            # train feature word2vec using column i
            # if len(columns)>0:
            #     print(str(columns[i]))
            #     print
            # else:
            print("Column {}...".format(i))
            # get train and test data
            train_data = X_dataTrain[:,i]
            test_data = X_dataTest[:,i]
            # initialize and train model
            tfidf = TfidfVectorizer(max_features=100)
            tfidf.fit(train_data)
            vocab = list(tfidf.vocabulary_.keys())
            vocab.sort()
            print(vocab, flush=True)
            print
            # transform train and test texts to w2v mean
            train_tfidf = tfidf.transform(train_data)
            test_tfidf = tfidf.transform(test_data)
            # if first execution, save only features
            if X_train == None:
                X_train = train_tfidf
                X_test = test_tfidf
            # concatenate existing features
            else:
                X_train = sp.hstack((X_train, train_tfidf), format='csr')
                #np.concatenate((X_train, train_tfidf), axis=1)
                X_test = sp.hstack((X_test, test_tfidf), format='csr')
                #np.concatenate((X_test, test_tfidf), axis=1)
            # save model
            models.append(tfidf)
            # except:
            #     print("Empty vocab for column {}".format(i))
            #     pass
        return(X_train, X_test)


    # Normalization method:

    # In[6]:


    # normalize features
    def normalization(X_train, X_test):
        from sklearn.preprocessing import MinMaxScaler
        from sklearn.preprocessing import MaxAbsScaler
        # scaler = MinMaxScaler()
        scaler = MaxAbsScaler()
        scaler.fit(X_train)
        XX_train = scaler.transform(X_train)
        XX_test = scaler.transform(X_test)
        return(XX_train, XX_test)


    # Iterate over months in test data:

    # In[7]:


    import numpy as np
    from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
    from sklearn.ensemble import RandomForestClassifier# as Classifier
    # from sklearn.linear_model import SGDClassifier as Classifier
    # group by year-month
    dataTestTime = dataTest.groupby([dataTest[TIME_COL].dt.year, dataTest[TIME_COL].dt.month])
    # get data train labels
    y_train = np.array(dataTrain["label"])
    # remove unused columns from dataTrain
    # remove unused columns from dataTrain
    print(data.columns.values)
    for c in UNUSED_COLUMNS:
        # del data[c]
        del dataTrain[c]
        # del dataTest[c]
    # get dataTrain values
    X_dataTrain = dataTrain.values
    # arrays to save information
    accs = [] # accuracy
    f1s = [] # f1score
    recall = [] # recall
    precision = [] # precision
    years = []
    months = []
    # iterate over year and month
    for (year, month), dataTestMonth in dataTestTime:
        # get data test labels
        y_test = np.array(dataTestMonth["label"])
        # remove unused columns from data test
        for c in UNUSED_COLUMNS:
            del dataTestMonth[c]
        # get dataTestMonth values
        X_dataTest = dataTestMonth.values
        # feature extraction
        X_train, X_test = feature_extraction(X_dataTrain, X_dataTest)
        # normalization
        XX_train, XX_test = normalization(X_train, X_test)
        # classifier
        clf = RandomForestClassifier(random_state=0)
        # clf = Classifier(random_state=0)
        # train classifier
        clf.fit(XX_train,y_train)
        # predict test data
        y_pred = clf.predict(XX_test)
        # update train data and labels with actual month
        X_dataTrain = np.append(X_dataTrain, X_dataTest, axis=0)
        y_train = np.concatenate((y_train, np.array(y_test)), axis=0)
        print("{}-{}".format(year,month))
        # save metrics
        f1 = f1_score(y_test, y_pred)
        acc = accuracy_score(y_test, y_pred)
        re = recall_score(y_test, y_pred)
        pr = precision_score(y_test, y_pred)
        if (f1 !=0) and (re != 0) and (pr != 0):
            accs.append(acc)
            f1s.append(f1)
            recall.append(re)
            precision.append(pr)
            years.append(year)
            months.append(month)
            print(acc)


    # Plot accuracy and f1score:

    # In[8]:


    import matplotlib.pyplot as plt
    # clear zero results
    # interval of months to plot
    months_interval = 1
    # months to plot
    plt_months = []
    # for i, m in enumerate(months):
    #     if (i%months_interval==0):
    #         plt_months.append(m)

    # plot years bars
    last_year = years[0]
    plt.axvline(-0.1,color="gray",linewidth=0.5)
    plt.text(0.2,0.57,last_year, color="gray")
    x_ind = 0
    n_changes = 0
    x_inds = []
    for i, y in enumerate(years):
        if y!=last_year:
            print("oe")
            plt.axvline(i,color="gray",linewidth=0.5)
            plt.text(i+0.3,0.57,y, color="gray")
            last_year = y
            plt_months.append("...")
            plt_months.append(months[i])
            x_ind = x_ind + 1
            n_changes = n_changes + 1
            x_inds.append(x_ind)
        else:
            plt_months.append(months[i])
            x_inds.append(x_ind)
            x_ind = x_ind + 1
        print(x_inds)
    plt.plot(x_inds, accs, label="Accuracy")
    plt.plot(x_inds, f1s, color="red", label="F1Score")
    # plot months
    plt.xticks(range(0,len(plt_months),months_interval), (plt_months))
    plt.xlabel("Month")
    plt.ylabel("Accuracy X F1Score")
    plt.title("Incremental Windowed Classifier Update - DREBIN")
    plt.legend(loc="center right", bbox_to_anchor=(1, 0.2))
    plt.xlim(-0.33,len(plt_months)-0.66)
    plt.savefig("figures/exp_3_af_{}_rf.pdf".format(TRAIN_NROWS))
    plt.savefig("figures/exp_3_af_{}_rf.png".format(TRAIN_NROWS))
    plt.savefig("figures/exp_3_af_{}_rf.jpg".format(TRAIN_NROWS))
    plt.show()


    # In[8]:


    import matplotlib.pyplot as plt
    # plt.plot(recall, color="green", label="Recall")
    # plt.plot(precision, color="goldenrod", label="Precision")
    import matplotlib.pyplot as plt
    # plt.plot(recall, color="green", label="Recall")
    # plt.plot(precision, color="goldenrod", label="Precision")
    # clear zero results
    # interval of months to plot
    months_interval = 1
    # months to plot
    plt_months = []
    # for i, m in enumerate(months):
    #     if (i%months_interval==0):
    #         plt_months.append(m)

    # plot years bars
    last_year = years[0]
    plt.axvline(-0.1,color="gray",linewidth=0.5)
    plt.text(0.2,0.4,last_year, color="gray")
    x_ind = 0
    n_changes = 0
    x_inds = []
    for i, y in enumerate(years):
        if y!=last_year:
            print("oe")
            plt.axvline(i,color="gray",linewidth=0.5)
            plt.text(i+0.3,0.4,y, color="gray")
            last_year = y
            plt_months.append("...")
            plt_months.append(months[i])
            x_ind = x_ind + 1
            n_changes = n_changes + 1
            x_inds.append(x_ind)
        else:
            plt_months.append(months[i])
            x_inds.append(x_ind)
            x_ind = x_ind + 1
        print(x_inds)
    plt.plot(x_inds, recall, 's-', color="green", label="Recall")
    plt.plot(x_inds, precision, 'o-', color="goldenrod", label="Precision")
    # plot months
    plt.xticks(range(0,len(plt_months),months_interval), (plt_months))

    plt.xlabel("Month")
    plt.ylabel("Recall X Precision")
    plt.title("AndroZoo Incremental Windowed Classifier Update")
    plt.legend(loc="center right", bbox_to_anchor=(1, 0.2))
    plt.xlim(-0.33,len(plt_months)-0.66)
    plt.savefig("figures/exp_3_rp_{}_rf_.pdf".format(TRAIN_NROWS))
    plt.savefig("figures/exp_3_rp_{}_rf_.png".format(TRAIN_NROWS))
    plt.savefig("figures/exp_3_rp_{}_rf_.jpg".format(TRAIN_NROWS))
    plt.show()
    print("Avg Accuracy:", np.mean(accs))
    print("Avg F1Score:", np.mean(f1s))
    print("Avg Recall:", np.mean(recall))
    print("Avg Precision:", np.mean(precision))

    f = open("results/exp_3_rf_{}.txt".format(TRAIN_NROWS), "a")
    f.write("Accuracy: " + str(np.mean(accs)) + "\n")
    f.write("Overall F1Score: " + str(np.mean(f1s)) + "\n")
    f.write("Overall Recall: " + str(np.mean(recall)) + "\n")
    f.write("Overall Precision: " + str(np.mean(precision)) + "\n")
    # f.write("Confusion Matrix:\n")
    # f.write(confusion_matrix(true,pred))
    # In[ ]:
    # f.write("Drifts: " + str(drifts) + "\n")
    # f.write("# of Drifts: " + str(len(drifts)))
    f.close()

